{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = pd.read_pickle('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/annotation.pkl')\n",
    "input_data = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/input_signal.pt')\n",
    "output_data = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/output_signal.pt')\n",
    "raw_signal = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/raw_signals.pt')\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "torch_ref_rr = torch.from_numpy(reference_rr)\n",
    "train_ids = annotation.loc[annotation['patient_id']<13]\n",
    "test_ids = annotation.loc[annotation['patient_id']>=13]\n",
    "\n",
    "x_train_data = input_data[torch.from_numpy(training_ids.values)]\n",
    "x_test_data = input_data[torch.from_numpy(~(training_ids.values))]\n",
    "y_train_data = output_data[torch.from_numpy(training_ids.values)]\n",
    "y_test_data = output_data[torch.from_numpy(~(training_ids.values))]\n",
    "\n",
    "x_train_ref_rr = torch_ref_rr[torch.from_numpy(training_ids.values)]\n",
    "x_test_ref_rr = torch_ref_rr[torch.from_numpy(~(training_ids.values))]\n",
    "raw_train_signals = raw_signal[torch.from_numpy(training_ids.values)]\n",
    "raw_test_signals = raw_signal[torch.from_numpy(~(training_ids.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_train_resp = TensorDataset(x_train_data , y_train_data)\n",
    "trainloader_resp = DataLoader(torch_train_resp, batch_size = 128 , shuffle=True)\n",
    "\n",
    "torch_test_resp = TensorDataset(x_test_data , y_test_data)\n",
    "testloader_resp = DataLoader(torch_test_resp, batch_size = 128 , shuffle=False)\n",
    "#-----------------------------------------------------------------------------------------\n",
    "torch_train_rr = TensorDataset(x_train_data , x_train_ref_rr)\n",
    "trainloader_rr = DataLoader(torch_train_rr, batch_size = 128 , shuffle=True)\n",
    "\n",
    "torch_test_rr = TensorDataset(x_test_data , x_test_ref_rr)\n",
    "testloader_rr = DataLoader(torch_test_rr, batch_size = 128 , shuffle=False)\n",
    "#-----------------------------------------------------------------------------------------\n",
    "torch_train_resp_rr = TensorDataset(x_train_data ,y_train_data, x_train_ref_rr)\n",
    "trainloader_resp_rr = DataLoader(torch_train_resp_rr, batch_size = 128 , shuffle=True)\n",
    "\n",
    "torch_test_resp_rr = TensorDataset(x_test_data ,y_test_data, x_test_ref_rr)\n",
    "testloader_resp_rr = DataLoader(torch_test_resp_rr, batch_size = 128 , shuffle=False)\n",
    "#-----------------------------------------------------------------------------------------\n",
    "torch_train_ecg_resp = TensorDataset(raw_train_signals , y_train_data)\n",
    "trainloader_ecg_resp = DataLoader(torch_train_ecg_resp, batch_size = 128 , shuffle=True)\n",
    "\n",
    "torch_test_ecg_resp = TensorDataset(raw_test_signals , y_test_data)\n",
    "testloader_ecg_resp = DataLoader(torch_test_ecg_resp, batch_size = 128 , shuffle=False)\n",
    "#-----------------------------------------------------------------------------------------\n",
    "torch_train_ecg_rr = TensorDataset(raw_train_signals , x_train_ref_rr)\n",
    "trainloader_ecg_rr = DataLoader(torch_train_ecg_rr, batch_size = 128 , shuffle=True)\n",
    "\n",
    "torch_test_ecg_rr = TensorDataset(raw_test_signals , x_test_ref_rr)\n",
    "testloader_ecg_rr = DataLoader(torch_test_ecg_rr, batch_size = 128 , shuffle=False)\n",
    "#----------------------------------------------------------------------------------------\n",
    "torch_train_ecg_rr_resp = TensorDataset(raw_train_signals , y_train_data,x_train_ref_rr)\n",
    "trainloader_ecg_rr_resp = DataLoader(torch_train_ecg_rr_resp, batch_size = 128 , shuffle=True)\n",
    "\n",
    "torch_test_ecg_rr_resp = TensorDataset(raw_test_signals , y_test_data,x_test_ref_rr)\n",
    "testloader_ecg_rr_resp = DataLoader(torch_test_ecg_rr_resp, batch_size = 128 , shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20943613\n"
     ]
    }
   ],
   "source": [
    "best_model = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/SIGNAL_0.005/2021_03_27_11_47/model.pt')\n",
    "best_model_parameters = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/SIGNAL_0.005/2021_03_27_11_47/parameters.pt')\n",
    "best_model.eval()\n",
    "test_loss = []\n",
    "final_output = torch.tensor([]).cuda()\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "for i, (x_resp,y_resp) in enumerate(testloader_resp):\n",
    "    x_resp = x_resp.float().cuda()\n",
    "    y_resp = y_resp.float().view(-1,1,y_resp.shape[-1]).cuda() \n",
    "    model_output = best_model(x_resp)\n",
    "    model_output = model_output.view(-1,1,model_output.shape[-1])\n",
    "    #import pdb;pdb.set_trace()\n",
    "    loss = criterion(y_resp, model_output)\n",
    "    final_output = torch.cat((final_output , model_output) , dim= 0 )\n",
    "    test_loss.append(float(loss.cpu().data))\n",
    "final_resp_sig = final_output.detach().cpu().numpy()\n",
    "final_resp_sig = final_resp_sig.reshape(final_resp_sig.shape[0] , final_resp_sig.shape[2])\n",
    "ref_resp_sig = y_test_data.detach().cpu().numpy()\n",
    "pytorch_total_params = sum(p.numel() for p in best_model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-300,300])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-300 , 300])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbpB,fbpA = scipy.signal.butter(6,np.array([0.1,0.7])/2,btype='bandpass')\n",
    "filt_sig = []\n",
    "filt_ref_sig = []\n",
    "for item in final_resp_sig:\n",
    "    filt_sig.append(scipy.signal.filtfilt(fbpB,fbpA,item))\n",
    "for item in ref_resp_sig:\n",
    "    filt_ref_sig.append(scipy.signal.filtfilt(fbpB,fbpA,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_resp,extremas_resp = extremas_extraction(filt_sig)\n",
    "duration_ref_resp,extremas_ref_resp = extremas_extraction(filt_ref_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_resp = 240/duration_resp\n",
    "rr_ref = 240/duration_ref_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.abs(rr_resp - rr_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(error)\n",
    "rmse = np.sqrt(np.mean(error**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.668680240439738"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16647332\n"
     ]
    }
   ],
   "source": [
    "best_model = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/ENCODER_ONLY_0.005/2021_03_26_14_46/model.pt')\n",
    "best_model_parameters = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/ENCODER_ONLY_0.005/2021_03_26_14_46/parameters.pt')\n",
    "best_model.eval()\n",
    "test_loss = []\n",
    "final_output_rr = torch.tensor([]).cuda()\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "for i, (x_resp,y_rr) in enumerate(testloader_rr):\n",
    "    x_resp = x_resp.float().cuda()\n",
    "    y_rr = y_rr.float().cuda()\n",
    "    out_rr = best_model(x_resp)\n",
    "    #out_rr = out_rr.view(-1,1,model_output.shape[-1])\n",
    "    loss = 0.01*criterion(y_rr, out_rr)\n",
    "    final_output_rr = torch.cat((final_output_rr , out_rr) , dim= 0 )\n",
    "    test_loss.append(float(loss.cpu().data))\n",
    "\n",
    "output_rr = final_output_rr.detach().cpu().numpy()\n",
    "pytorch_total_params = sum(p.numel() for p in best_model.parameters())\n",
    "ref_rr = x_test_ref_rr.detach().cpu().numpy()\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.abs(output_rr - rr_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(error)\n",
    "rmse = np.sqrt(np.mean(error**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.418603258612834"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21688913\n"
     ]
    }
   ],
   "source": [
    "best_model = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/ENCODER_SIGNAL_MULTI_0.005/2021_03_28_17_10/model.pt')\n",
    "best_model_parameters = torch.load('/media/hticpose/drive1/Prithvi/PPG/PPG_FieldStudy/ENCODER_SIGNAL_MULTI_0.005/2021_03_28_17_10/parameters.pt')\n",
    "best_model.eval()\n",
    "test_loss = []\n",
    "final_output_rr = torch.tensor([]).cuda()\n",
    "final_output = torch.tensor([]).cuda()\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "criterion_rr = torch.nn.SmoothL1Loss()\n",
    "for i, (x_resp,y_resp,y_rr) in enumerate(testloader_resp_rr):\n",
    "    x_resp = x_resp.float().cuda()\n",
    "    y_resp = y_resp.float().view(-1,1,y_resp.shape[-1]).cuda() \n",
    "    y_rr = y_rr.float().cuda()\n",
    "    output_resp , out_rr = best_model(x_resp)\n",
    "    #out_rr = out_rr.view(-1,1,model_output.shape[-1])\n",
    "    loss_resp = criterion(y_resp, output_resp)\n",
    "    loss_rr = 0.01*criterion_rr(y_rr,out_rr)\n",
    "    total_loss = loss_resp+loss_rr\n",
    "    final_output_rr = torch.cat((final_output_rr , out_rr) , dim= 0 )\n",
    "    final_output = torch.cat((final_output , output_resp) , dim= 0 )\n",
    "    test_loss.append(float(total_loss.cpu().data))\n",
    "\n",
    "output_rr = final_output_rr.detach().cpu().numpy()\n",
    "final_resp_sig = final_output.detach().cpu().numpy()\n",
    "final_resp_sig = final_resp_sig.reshape(final_resp_sig.shape[0] , final_resp_sig.shape[2])\n",
    "ref_resp_sig = y_test_data.detach().cpu().numpy()\n",
    "pytorch_total_params = sum(p.numel() for p in best_model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbpB,fbpA = scipy.signal.butter(5,np.array([0.1,0.6])/2,btype='bandpass')\n",
    "filt_sig = []\n",
    "filt_ref_sig = []\n",
    "for item in final_resp_sig:\n",
    "    filt_sig.append(scipy.signal.filtfilt(fbpB,fbpA,item))\n",
    "for item in ref_resp_sig:\n",
    "    filt_ref_sig.append(scipy.signal.filtfilt(fbpB,fbpA,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_resp,extremas_resp = extremas_extraction(filt_sig)\n",
    "duration_ref_resp,extremas_ref_resp = extremas_extraction(filt_ref_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_resp = 240/duration_resp\n",
    "rr_ref = 240/duration_ref_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.abs(output_rr - rr_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(error)\n",
    "rmse = np.sqrt(np.mean(error**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.927675917397163"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6580598238000075"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
